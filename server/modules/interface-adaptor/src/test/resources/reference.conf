akka {
  stdout-loglevel = off // defaults to WARNING can be disabled with off. The stdout-loglevel is only in effect during system startup and shutdown
  log-dead-letters-during-shutdown = on
  loglevel = DEBUG
  log-dead-letters = on
  log-config-on-start = off // Log the complete configuration at INFO level when the actor system is started

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    debug {
      receive = on // log all messages sent to an actor if that actors receive method is a LoggingReceive
      autoreceive = off // log all special messages like Kill, PoisoffPill etc sent to all actors
      lifecycle = off // log all actor lifecycle events of all actors
      fsm = off // enable logging of all events, transitioffs and timers of FSM Actors that extend LoggingFSM
      event-stream = off // enable logging of subscriptions (subscribe/unsubscribe) on the ActorSystem.eventStream
    }
    serializers {
      json = "truss.interfaceAdaptor.serialization.WalletEventJSONSerializer"
    }
    serialization-bindings {
      "truss.interfaceAdaptor.aggregate.WalletProtocol$Event" = json
    }
  }
}

akka.actor.allow-java-serialization = true

j5ik2o {

  dynamo-db-journal {
    class = "com.github.j5ik2o.akka.persistence.dynamodb.journal.DynamoDBJournal"
    plugin-dispatcher = "akka.actor.default-dispatcher"
  }

  dynamo-db-snapshot {
    class = "com.github.j5ik2o.akka.persistence.dynamodb.snapshot.DynamoDBSnapshotStore"
    plugin-dispatcher = "akka.actor.default-dispatcher"
  }

  dynamo-db-read-journal {
    class = "com.github.j5ik2o.akka.persistence.dynamodb.query.DynamoDBReadJournalProvider"
    write-plugin = "j5ik2o.dynamo-db-journal"
  }

}

j5ik2o {
  kafka-journal {
    class = "com.github.j5ik2o.akka.persistence.kafka.journal.KafkaJournal"
    topic-prefix = "journal-"
    topic-resolver-class-name = "com.github.j5ik2o.akka.persistence.kafka.resolver.KafkaTopicResolver$PersistenceId"
    partition-resolver-class-name = "com.github.j5ik2o.akka.persistence.kafka.resolver.KafkaPartitionResolver$PartitionZero"
    bootstrap-servers = ["localhost:6001"]
    producer {
      # Config path of Akka Discovery method
      # "akka.discovery" to use the Akka Discovery method configured for the ActorSystem
      discovery-method = akka.discovery

      # Set a service name for use with Akka Discovery
      # https://doc.akka.io/docs/alpakka-kafka/current/discovery.html
      service-name = ""

      # Timeout for getting a reply from the discovery-method lookup
      resolve-timeout = 3 seconds

      # Tuning parameter of how many sends that can run in parallel.
      # In 2.0.0: changed the default from 100 to 10000
      parallelism = 1

      # Duration to wait for `KafkaProducer.close` to finish.
      close-timeout = 60s

      # Call `KafkaProducer.close` when the stream is shutdown. This is important to override to false
      # when the producer instance is shared across multiple producer stages.
      close-on-producer-stop = true

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the producer stages. Some blocking may occur.
      # When this value is empty, the dispatcher configured for the stream
      # will be used.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
      # for exactly-once-semantics processing.
      eos-commit-interval = 100ms

      # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
      # can be defined in this configuration section.
      kafka-clients {
      }
    }
    consumer {
      # Config path of Akka Discovery method
      # "akka.discovery" to use the Akka Discovery method configured for the ActorSystem
      discovery-method = akka.discovery

      # Set a service name for use with Akka Discovery
      # https://doc.akka.io/docs/alpakka-kafka/current/discovery.html
      service-name = ""

      # Timeout for getting a reply from the discovery-method lookup
      resolve-timeout = 3 seconds

      # Tuning property of scheduled polls.
      # Controls the interval from one scheduled poll to the next.
      poll-interval = 50ms

      # Tuning property of the `KafkaConsumer.poll` parameter.
      # Note that non-zero value means that the thread that
      # is executing the stage will be blocked. See also the `wakup-timeout` setting below.
      poll-timeout = 50ms

      # The stage will delay stopping the internal actor to allow processing of
      # messages already in the stream (required for successful committing).
      # This can be set to 0 for streams using `DrainingControl`.
      stop-timeout = 30s

      # Duration to wait for `KafkaConsumer.close` to finish.
      close-timeout = 20s

      # If offset commit requests are not completed within this timeout
      # the returned Future is completed `CommitTimeoutException`.
      # The `Transactional.source` waits this ammount of time for the producer to mark messages as not
      # being in flight anymore as well as waiting for messages to drain, when rebalance is triggered.
      commit-timeout = 15s

      # If commits take longer than this time a warning is logged
      commit-time-warning = 1s

      # Not relevant for Kafka after version 2.1.0.
      # If set to a finite duration, the consumer will re-send the last committed offsets periodically
      # for all assigned partitions. See https://issues.apache.org/jira/browse/KAFKA-4682.
      commit-refresh-interval = infinite

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the KafkaConsumerActor. Some blocking may occur.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
      # can be defined in this configuration section.
      kafka-clients {
        # Disable auto-commit by default
        enable.auto.commit = false
        group.id = "test"
      }

      # Time to wait for pending requests when a partition is closed
      wait-close-partition = 500ms

      # Limits the query to Kafka for a topic's position
      position-timeout = 5s

      # When using `AssignmentOffsetsForTimes` subscriptions: timeout for the
      # call to Kafka's API
      offset-for-times-timeout = 5s

      # Timeout for akka.kafka.Metadata requests
      # This value is used instead of Kafka's default from `default.api.timeout.ms`
      # which is 1 minute.
      metadata-request-timeout = 5s

      # Interval for checking that transaction was completed before closing the consumer.
      # Used in the transactional flow for exactly-once-semantics processing.
      eos-draining-check-interval = 30ms

      # Issue warnings when a call to a partition assignment handler method takes
      # longer than this.
      partition-handler-warning = 5s

      # Settings for checking the connection to the Kafka broker. Connection checking uses `listTopics` requests with the timeout
      # configured by `consumer.metadata-request-timeout`
      connection-checker {

        #Flag to turn on connection checker
        enable = false

        # Amount of attempts to be performed after a first connection failure occurs
        # Required, non-negative integer
        max-retries = 3

        # Interval for the connection check. Used as the base for exponential retry.
        check-interval = 15s

        # Check interval multiplier for backoff interval
        # Required, positive number
        backoff-factor = 2.0
      }
    }
  }

  kafka-snapshot-store {
    class = "com.github.j5ik2o.akka.persistence.kafka.snapshot.KafkaSnapshotStore"
    topic-prefix = "snapshot-"
    topic-resolver-class-name = "com.github.j5ik2o.akka.persistence.kafka.resolver.KafkaTopicResolver$PersistenceId"
    partition-resolver-class-name = "com.github.j5ik2o.akka.persistence.kafka.resolver.KafkaPartitionResolver$PartitionZero"
    bootstrap-servers = ["localhost:6001"]
    producer {
      # Config path of Akka Discovery method
      # "akka.discovery" to use the Akka Discovery method configured for the ActorSystem
      discovery-method = akka.discovery

      # Set a service name for use with Akka Discovery
      # https://doc.akka.io/docs/alpakka-kafka/current/discovery.html
      service-name = ""

      # Timeout for getting a reply from the discovery-method lookup
      resolve-timeout = 3 seconds

      # Tuning parameter of how many sends that can run in parallel.
      # In 2.0.0: changed the default from 100 to 10000
      parallelism = 1

      # Duration to wait for `KafkaProducer.close` to finish.
      close-timeout = 60s

      # Call `KafkaProducer.close` when the stream is shutdown. This is important to override to false
      # when the producer instance is shared across multiple producer stages.
      close-on-producer-stop = true

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the producer stages. Some blocking may occur.
      # When this value is empty, the dispatcher configured for the stream
      # will be used.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
      # for exactly-once-semantics processing.
      eos-commit-interval = 100ms

      # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
      # can be defined in this configuration section.
      kafka-clients {
      }
    }
    consumer {
      # Config path of Akka Discovery method
      # "akka.discovery" to use the Akka Discovery method configured for the ActorSystem
      discovery-method = akka.discovery

      # Set a service name for use with Akka Discovery
      # https://doc.akka.io/docs/alpakka-kafka/current/discovery.html
      service-name = ""

      # Timeout for getting a reply from the discovery-method lookup
      resolve-timeout = 3 seconds

      # Tuning property of scheduled polls.
      # Controls the interval from one scheduled poll to the next.
      poll-interval = 50ms

      # Tuning property of the `KafkaConsumer.poll` parameter.
      # Note that non-zero value means that the thread that
      # is executing the stage will be blocked. See also the `wakup-timeout` setting below.
      poll-timeout = 50ms

      # The stage will delay stopping the internal actor to allow processing of
      # messages already in the stream (required for successful committing).
      # This can be set to 0 for streams using `DrainingControl`.
      stop-timeout = 30s

      # Duration to wait for `KafkaConsumer.close` to finish.
      close-timeout = 20s

      # If offset commit requests are not completed within this timeout
      # the returned Future is completed `CommitTimeoutException`.
      # The `Transactional.source` waits this ammount of time for the producer to mark messages as not
      # being in flight anymore as well as waiting for messages to drain, when rebalance is triggered.
      commit-timeout = 15s

      # If commits take longer than this time a warning is logged
      commit-time-warning = 1s

      # Not relevant for Kafka after version 2.1.0.
      # If set to a finite duration, the consumer will re-send the last committed offsets periodically
      # for all assigned partitions. See https://issues.apache.org/jira/browse/KAFKA-4682.
      commit-refresh-interval = infinite

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the KafkaConsumerActor. Some blocking may occur.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
      # can be defined in this configuration section.
      kafka-clients {
        # Disable auto-commit by default
        enable.auto.commit = false
        group.id = "test"
      }

      # Time to wait for pending requests when a partition is closed
      wait-close-partition = 500ms

      # Limits the query to Kafka for a topic's position
      position-timeout = 5s

      # When using `AssignmentOffsetsForTimes` subscriptions: timeout for the
      # call to Kafka's API
      offset-for-times-timeout = 5s

      # Timeout for akka.kafka.Metadata requests
      # This value is used instead of Kafka's default from `default.api.timeout.ms`
      # which is 1 minute.
      metadata-request-timeout = 5s

      # Interval for checking that transaction was completed before closing the consumer.
      # Used in the transactional flow for exactly-once-semantics processing.
      eos-draining-check-interval = 30ms

      # Issue warnings when a call to a partition assignment handler method takes
      # longer than this.
      partition-handler-warning = 5s

      # Settings for checking the connection to the Kafka broker. Connection checking uses `listTopics` requests with the timeout
      # configured by `consumer.metadata-request-timeout`
      connection-checker {

        #Flag to turn on connection checker
        enable = false

        # Amount of attempts to be performed after a first connection failure occurs
        # Required, non-negative integer
        max-retries = 3

        # Interval for the connection check. Used as the base for exponential retry.
        check-interval = 15s

        # Check interval multiplier for backoff interval
        # Required, positive number
        backoff-factor = 2.0
      }
    }
  }
}

